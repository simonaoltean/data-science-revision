{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p46AGtsWNdju"
   },
   "source": [
    "# Matrices\n",
    "\n",
    "Matrices are a neat way of organizing data for use in linear operations.\n",
    "\n",
    "An $ n \\times k $ matrix is a rectangular array $ A $ of numbers with $ n $ rows and $ k $ columns:\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1k} \\\\\n",
    "    a_{21} & a_{22} & \\cdots & a_{2k} \\\\\n",
    "    \\vdots & \\vdots &  & \\vdots \\\\\n",
    "    a_{n1} & a_{n2} & \\cdots & a_{nk}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Often, the numbers in the matrix represent things in the real world like\n",
    "\n",
    "- coefficients in a system of equations.\n",
    "\n",
    "- rows being observations, columns being attributes of these observations (a dataframe)\n",
    "\n",
    "For obvious reasons, the matrix $ A $ is also called a vector if either $ n = 1 $ or $ k = 1 $.\n",
    "\n",
    "In the former case, $ A $ is called a *row vector*, while in the latter it is called a *column vector*.\n",
    "\n",
    "If $ n = k $, then $ A $ is called *square*.\n",
    "\n",
    "The matrix formed by replacing $ a_{ij} $ by $ a_{ji} $ for every $ i $ and $ j $ is called the *transpose* of $ A $ and denoted $ A' $ or $ A^{\\top} $.\n",
    "\n",
    "If $ A = A' $, then $ A $ is called *symmetric*.\n",
    "\n",
    "For a square matrix $ A $, the $ i $ elements of the form $ a_{ii} $ for $ i=1,\\ldots,n $ are called the *principal diagonal*.\n",
    "\n",
    "$ A $ is called *diagonal* if the only nonzero entries are on the principal diagonal.\n",
    "\n",
    "If, in addition to being diagonal, each element along the principal diagonal is equal to 1, then $ A $ is called the *identity matrix* and denoted by $ I $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srrdkj60Ndj8"
   },
   "source": [
    "### Matrix Operations\n",
    "\n",
    "Just as was the case for vectors, a number of algebraic operations are defined for matrices.\n",
    "\n",
    "Scalar multiplication and addition are immediate generalizations of the vector case:\n",
    "\n",
    "$$\n",
    "\\gamma A =\n",
    "\\gamma\n",
    "\\begin{bmatrix}\n",
    "    a_{11} &  \\cdots & a_{1k} \\\\\n",
    "    \\vdots & \\vdots  & \\vdots \\\\\n",
    "    a_{n1} &  \\cdots & a_{nk}\n",
    "\\end{bmatrix} :=\n",
    "\\begin{bmatrix}\n",
    "    \\gamma a_{11} & \\cdots & \\gamma a_{1k} \\\\\n",
    "    \\vdots & \\vdots & \\vdots \\\\\n",
    "    \\gamma a_{n1} & \\cdots & \\gamma a_{nk}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "A + B =\n",
    "\\begin{bmatrix}\n",
    "    a_{11} & \\cdots & a_{1k} \\\\\n",
    "    \\vdots & \\vdots & \\vdots \\\\\n",
    "    a_{n1} & \\cdots & a_{nk}\n",
    "\\end{bmatrix} +\n",
    "\\begin{bmatrix}\n",
    "    b_{11} & \\cdots & b_{1k} \\\\\n",
    "    \\vdots & \\vdots & \\vdots \\\\\n",
    "    b_{n1} & \\cdots & b_{nk}\n",
    "\\end{bmatrix} :=\n",
    "\\begin{bmatrix}\n",
    "    a_{11} + b_{11} &  \\cdots & a_{1k} + b_{1k} \\\\\n",
    "    \\vdots & \\vdots & \\vdots \\\\\n",
    "    a_{n1} + b_{n1} &  \\cdots & a_{nk} + b_{nk}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In the latter case, the matrices must have the same shape in order for the definition to make sense.\n",
    "\n",
    "# Multiplication\n",
    "\n",
    "We also have a convention for *multiplying* two matrices.\n",
    "\n",
    "The rule for matrix multiplication generalizes the idea of dot products discussed in vector algebra\n",
    "and is designed to make multiplication play well with basic linear operations.\n",
    "\n",
    "If $ A $ and $ B $ are two matrices, then their product $ A B $ is formed by taking as its\n",
    "$ i,j $-th element the dot product of the $ i $-th row of $ A $ and the\n",
    "$ j $-th column of $ B $.\n",
    "\n",
    "The [Wikipedia page](https://en.wikipedia.org/wiki/Matrix_multiplication) can help sort it, as well as this diagram:\n",
    "\n",
    "![](../assets/matrix_dot.png)\n",
    "\n",
    "If $ A $ is $ n \\times k $ and $ B $ is $ j \\times m $, then\n",
    "to multiply $ A $ and $ B $ we require $ k = j $, and the\n",
    "resulting matrix $ A B $ is $ n \\times m $.\n",
    "\n",
    "**memory trick**: Dot product is *joined on the inside dimensions* so $ n \\times (k \\cdot j) \\times m $\n",
    "\n",
    "As perhaps the most important special case, consider multiplying $ n \\times k $ matrix $ A $ and $ k \\times 1 $ column vector $ x $.\n",
    "\n",
    "According to the preceding rule, this gives us an $ n \\times 1 $ column vector\n",
    "\n",
    "\n",
    "<a id='equation-la-atx'></a>\n",
    "$$\n",
    "A x =\n",
    "\\begin{bmatrix}\n",
    "    a_{11} &  \\cdots & a_{1k} \\\\\n",
    "    \\vdots & \\vdots  & \\vdots \\\\\n",
    "    a_{n1} &  \\cdots & a_{nk}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    x_{1}  \\\\\n",
    "    \\vdots  \\\\\n",
    "    x_{k}\n",
    "\\end{bmatrix} :=\n",
    "\\begin{bmatrix}\n",
    "    a_{11} x_1 + \\cdots + a_{1k} x_k \\\\\n",
    "    \\vdots \\\\\n",
    "    a_{n1} x_1 + \\cdots + a_{nk} x_k\n",
    "\\end{bmatrix} \\tag{2}\n",
    "$$\n",
    "\n",
    ">**Note**\n",
    ">\n",
    ">$ A B $ and $ B A $ are not generally the same thing.\n",
    "\n",
    "Another important special case is the identity matrix.\n",
    "\n",
    "You should check that if $ A $ is $ n \\times k $ and $ I $ is the $ k \\times k $ identity matrix, then $ AI = A $.\n",
    "\n",
    "If $ I $ is the $ n \\times n $ identity matrix, then $ IA = A $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgiK8ek3Ndj_"
   },
   "source": [
    "### Matrices in NumPy\n",
    "\n",
    "NumPy arrays are also used as matrices, and have fast, efficient functions and methods for all the standard matrix operations.\n",
    "\n",
    "You can create them manually from tuples of tuples (or lists of lists) as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "id": "AqKg3gJBNdkA",
    "outputId": "0599f9e2-1058-417e-89b2-9f58c318bb6a"
   },
   "outputs": [],
   "source": [
    "A = [(1, 2),\n",
    "     (3, 4)]\n",
    "\n",
    "type(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "id": "z7HOOXjONdkC",
    "outputId": "66c6a2fc-ee1e-4231-8ada-bf3ce4243844"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array(A)\n",
    "\n",
    "print(\"shape\", A.shape)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k37xryy4NdkD"
   },
   "source": [
    "The `shape` attribute is a tuple giving the number of rows and columns —\n",
    "see [here](https://python-programming.quantecon.org/numpy.html#shape-and-dimension)\n",
    "for more discussion.\n",
    "\n",
    "To get the transpose of `A`, use `A.transpose()` or, more simply, `A.T`.\n",
    "\n",
    "There are many convenient functions for creating common matrices (matrices of zeros,\n",
    "ones, etc.) — see [here](https://python-programming.quantecon.org/numpy.html#creating-arrays).\n",
    "\n",
    "Since operations are performed elementwise by default, scalar multiplication and addition have very natural syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "id": "iUDA1LkTNdkD",
    "outputId": "edeb9b3d-80ef-4aea-ec6b-33aef954ffed"
   },
   "outputs": [],
   "source": [
    "A = np.identity(3)\n",
    "B = np.ones((3, 3))\n",
    "2 * A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "id": "aKN7ZIfPNdkE",
    "outputId": "17b7c370-78fb-4e7f-8760-5ce68f5107e9"
   },
   "outputs": [],
   "source": [
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InwGRwGGNdkF"
   },
   "source": [
    "To multiply matrices we use the `@` symbol.\n",
    "\n",
    "In particular, `A @ B` is matrix multiplication, whereas `A * B` is element-by-element multiplication.\n",
    "\n",
    "See [here](https://python-programming.quantecon.org/numpy.html#matrix-multiplication) for more discussion.\n",
    "\n",
    "\n",
    "<a id='la-linear-map'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DW-I2slNdkF"
   },
   "source": [
    "### Matrices as Maps\n",
    "\n",
    "\n",
    "<a id='index-11'></a>\n",
    "Each $ n \\times k $ matrix $ A $ can be identified with a function $ f(x) = Ax $ that maps $ x \\in \\mathbb R ^k $ into $ y = Ax \\in \\mathbb R ^n $.\n",
    "\n",
    "These kinds of functions have a special property: they are *linear*.\n",
    "\n",
    "A function $ f \\colon \\mathbb R ^k \\to \\mathbb R ^n $ is called *linear* if, for all $ x, y \\in \\mathbb R ^k $ and all scalars $ \\alpha, \\beta $, we have\n",
    "\n",
    "$$\n",
    "f(\\alpha x + \\beta y) = \\alpha f(x) + \\beta f(y)\n",
    "$$\n",
    "\n",
    "You can check that this holds for the function $ f(x) = A x + b $ when $ b $ is the zero vector and fails when $ b $ is nonzero.\n",
    "\n",
    "In fact, it’s [known](https://en.wikipedia.org/wiki/Linear_map#Matrices) that $ f $ is linear if and *only if* there exists a matrix $ A $ such that $ f(x) = Ax $ for all $ x $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOicLhygNdkG"
   },
   "source": [
    "## Motivating example: Back To Polynomials\n",
    "\n",
    "Representing polynomials as vectors is powerful when we want to solve multiple equations at the same time. For instance if we have the following equations:\n",
    "\n",
    "$3x + 2y - z = 1$  \n",
    "$2x - 2y + 4z = -2$  \n",
    "$-x + 0.5y - z = 0$  \n",
    "\n",
    "The **solution** would be \n",
    "\n",
    "$$x=1; y=-2; z=-2$$\n",
    "\n",
    "We can rearrange the problem as a matrix problem with the equations matrix on the left and the solution vector on the right:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "3x & 2y & -1z\n",
    "\\\\ 2x & -2y & 4z\n",
    "\\\\ -1x & 0.5y & -1z\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} 1\\\\ -2\\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Which can be rearranged as:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "3 & 2 & -1\n",
    "\\\\ 2 & -2 & 4\n",
    "\\\\ -1 & 0.5 & -1\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} x\\\\ y\\\\ z \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} 1\\\\ -2\\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "One thing to note is that for $n$ equations with $n$ unknowns we can generally solve for the unknowns.\n",
    "\n",
    "<img src=\"../assets/3_equation_graph.png\" style=\"max-width:500px;\" />\n",
    "\n",
    "The problem we face is to determine a vector $ x \\in \\mathbb R ^k $ that solves the equation problem, taking $ y $ and $ A $ as given.\n",
    "\n",
    "This is a special case of a more general problem: Find an $ x $ such that $ y = f(x) $.\n",
    "\n",
    "Given an arbitrary function $ f $ and a $ y $, is there always an $ x $ such that $ y = f(x) $?\n",
    "\n",
    "If so, is it always unique?\n",
    "\n",
    "The answer to both these questions is negative, as the next figure shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "html-class": "collapse",
    "id": "bqAo9HBINdkH",
    "outputId": "169b69a3-6d76-4c3c-abc2-8788fb4ebb60"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return 0.6 * np.cos(4 * x) + 1.4\n",
    "\n",
    "\n",
    "xmin, xmax = -1, 1\n",
    "x = np.linspace(xmin, xmax, 160)\n",
    "y = f(x)\n",
    "ya, yb = np.min(y), np.max(y)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "for ax in axes:\n",
    "    # Set the axes through the origin\n",
    "    for spine in ['left', 'bottom']:\n",
    "        ax.spines[spine].set_position('zero')\n",
    "    for spine in ['right', 'top']:\n",
    "        ax.spines[spine].set_color('none')\n",
    "\n",
    "    ax.set(ylim=(-0.6, 3.2), xlim=(xmin, xmax),\n",
    "           yticks=(), xticks=())\n",
    "\n",
    "    ax.plot(x, y, 'k-', lw=2, label='$f$')\n",
    "    ax.fill_between(x, ya, yb, facecolor='blue', alpha=0.05)\n",
    "    ax.vlines([0], ya, yb, lw=3, color='blue', label='range of $f$')\n",
    "    ax.text(0.04, -0.3, '$0$', fontsize=16)\n",
    "\n",
    "ax = axes[0]\n",
    "\n",
    "ax.legend(loc='upper right', frameon=False)\n",
    "ybar = 1.5\n",
    "ax.plot(x, x * 0 + ybar, 'k--', alpha=0.5)\n",
    "ax.text(0.05, 0.8 * ybar, '$y$', fontsize=16)\n",
    "for i, z in enumerate((-0.35, 0.35)):\n",
    "    ax.vlines(z, 0, f(z), linestyle='--', alpha=0.5)\n",
    "    ax.text(z, -0.2, f'$x_{i}$', fontsize=16)\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "ybar = 2.6\n",
    "ax.plot(x, x * 0 + ybar, 'k--', alpha=0.5)\n",
    "ax.text(0.04, 0.91 * ybar, '$y$', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb7hF43BNdkI"
   },
   "source": [
    "In the first plot, there are multiple solutions, as the function is not one-to-one, while\n",
    "in the second there are no solutions, since $ y $ lies outside the range of $ f $.\n",
    "\n",
    "Can we impose conditions on $ A $ in an equation that rule out these problems?\n",
    "\n",
    "In this context, the most important thing to recognize about the expression\n",
    "$ Ax $ is that it corresponds to a linear combination of the columns of $ A $.\n",
    "\n",
    "In particular, if $ a_1, \\ldots, a_k $ are the columns of $ A $, then\n",
    "\n",
    "$$\n",
    "Ax = x_1 a_1 + \\cdots + x_k a_k\n",
    "$$\n",
    "\n",
    "Hence the range of $ f(x) = Ax $ is exactly the span of the columns of $ A $.\n",
    "\n",
    "We want the range to be large so that it contains arbitrary $ y $.\n",
    "\n",
    "As you might recall, the condition that we want for the span to be large is [linear independence](#la-li).\n",
    "\n",
    "A happy fact is that linear independence of the columns of $ A $ also gives us uniqueness.\n",
    "\n",
    "Indeed, it follows that if $ \\{a_1, \\ldots, a_k\\} $ are linearly independent and $ y = Ax = x_1 a_1 + \\cdots + x_k a_k $, then no $ z \\not= x $ satisfies $ y = Az $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6W3Y-33uNdkJ"
   },
   "source": [
    "### The Square Matrix Case\n",
    "\n",
    "Let’s discuss some more details, starting with the case where $ A $ is $ n \\times n $.\n",
    "\n",
    "This is the familiar case where the number of unknowns equals the number of equations.\n",
    "\n",
    "For arbitrary $ y \\in \\mathbb R ^n $, we hope to find a unique $ x \\in \\mathbb R ^n $ such that $ y = Ax $.\n",
    "\n",
    "In view of the observations immediately above, if the columns of $ A $ are\n",
    "linearly independent, then their span, and hence the range of $ f(x) =\n",
    "Ax $, is all of $ \\mathbb R ^n $.\n",
    "\n",
    "Hence there always exists an $ x $ such that $ y = Ax $.\n",
    "\n",
    "Moreover, the solution is unique.\n",
    "\n",
    "In particular, the following are equivalent\n",
    "\n",
    "1. The columns of $ A $ are linearly independent.  \n",
    "1. For any $ y \\in \\mathbb R ^n $, the equation $ y = Ax $ has a unique solution.  \n",
    "\n",
    "\n",
    "The property of having linearly independent columns is sometimes expressed as having *full column rank*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDI3HmzrNdkK"
   },
   "source": [
    "#### Inverse Matrices\n",
    "\n",
    "\n",
    "<a id='index-13'></a>\n",
    "Can we give some sort of expression for the solution?\n",
    "\n",
    "If $ y $ and $ A $ are scalar with $ A \\not= 0 $, then the\n",
    "solution is $ x = A^{-1} y $.\n",
    "\n",
    "A similar expression is available in the matrix case.\n",
    "\n",
    "In particular, if square matrix $ A $ has full column rank, then it possesses a multiplicative\n",
    "*inverse matrix* $ A^{-1} $, with the property that $ A A^{-1} = A^{-1} A = I $.\n",
    "\n",
    "As a consequence, if we pre-multiply both sides of $ y = Ax $ by $ A^{-1} $, we get $ x = A^{-1} y $.\n",
    "\n",
    "This is the solution that we’re looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7Pigg18NdkL"
   },
   "source": [
    "#### Determinants\n",
    "\n",
    "\n",
    "<a id='index-14'></a>\n",
    "Another quick comment about square matrices is that to every such matrix we\n",
    "assign a unique number called the *determinant* of the matrix — you can find\n",
    "the expression for it [here](https://en.wikipedia.org/wiki/Determinant).\n",
    "\n",
    "If the determinant of $ A $ is not zero, then we say that $ A $ is\n",
    "*nonsingular*.\n",
    "\n",
    "Perhaps the most important fact about determinants is that $ A $ is nonsingular if and only if $ A $ is of full column rank.\n",
    "\n",
    "This gives us a useful one-number summary of whether or not a square matrix can be\n",
    "inverted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oolTp6zCNdkL"
   },
   "source": [
    "### More Rows than Columns\n",
    "\n",
    "This is the $ n \\times k $ case with $ n > k $.\n",
    "\n",
    "This case is very important in many settings, not least in the setting of linear regression (where $ n $ is the number of observations, and $ k $ is the number of explanatory variables).\n",
    "\n",
    "Given arbitrary $ y \\in \\mathbb R ^n $, we seek an $ x \\in \\mathbb R ^k $ such that $ y = Ax $.\n",
    "\n",
    "In this setting, the existence of a solution is highly unlikely.\n",
    "\n",
    "Without much loss of generality, let’s go over the intuition focusing on the case where the columns of\n",
    "$ A $ are linearly independent.\n",
    "\n",
    "It follows that the span of the columns of $ A $ is a $ k $-dimensional subspace of $ \\mathbb R ^n $.\n",
    "\n",
    "This span is very “unlikely” to contain arbitrary $ y \\in \\mathbb R ^n $.\n",
    "\n",
    "To see why, recall the [figure above](#la-3dvec), where $ k=2 $ and $ n=3 $.\n",
    "\n",
    "Imagine an arbitrarily chosen $ y \\in \\mathbb R ^3 $, located somewhere in that three-dimensional space.\n",
    "\n",
    "What’s the likelihood that $ y $ lies in the span of $ \\{a_1, a_2\\} $ (i.e., the two dimensional plane through these points)?\n",
    "\n",
    "In a sense, it must be very small, since this plane has zero “thickness”.\n",
    "\n",
    "As a result, in the $ n > k $ case we usually give up on existence.\n",
    "\n",
    "However, we can still seek the best approximation, for example, an\n",
    "$ x $ that makes the distance $ \\| y - Ax\\| $ as small as possible.\n",
    "\n",
    "To solve this problem, one can use either calculus or the theory of orthogonal\n",
    "projections.\n",
    "\n",
    "The solution is known to be $ \\hat x = (A'A)^{-1}A'y $ — see for example\n",
    "chapter 3 of <a href=_static/lecture_specific/linear_algebra/course_notes.pdf download>these notes</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p97DY1ToNdkN"
   },
   "source": [
    "### More Columns than Rows\n",
    "\n",
    "This is the $ n \\times k $ case with $ n < k $, so there are fewer\n",
    "equations than unknowns.\n",
    "\n",
    "In this case there are either no solutions or infinitely many — in other words, uniqueness never holds.\n",
    "\n",
    "For example, consider the case where $ k=3 $ and $ n=2 $.\n",
    "\n",
    "Thus, the columns of $ A $ consists of 3 vectors in $ \\mathbb R ^2 $.\n",
    "\n",
    "This set can never be linearly independent, since it is possible to find two vectors that span\n",
    "$ \\mathbb R ^2 $.\n",
    "\n",
    "(For example, use the canonical basis vectors)\n",
    "\n",
    "It follows that one column is a linear combination of the other two.\n",
    "\n",
    "For example, let’s say that $ a_1 = \\alpha a_2 + \\beta a_3 $.\n",
    "\n",
    "Then if $ y = Ax = x_1 a_1 + x_2 a_2 + x_3 a_3 $, we can also write\n",
    "\n",
    "$$\n",
    "y\n",
    "= x_1 (\\alpha a_2 + \\beta a_3) + x_2 a_2 + x_3 a_3\n",
    "= (x_1 \\alpha + x_2) a_2 + (x_1 \\beta + x_3) a_3\n",
    "$$\n",
    "\n",
    "In other words, uniqueness fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsFVlPTBNdkN"
   },
   "source": [
    "### Linear Equations with SciPy\n",
    "\n",
    "\n",
    "<a id='index-15'></a>\n",
    "Here’s an illustration of how to solve linear equations with SciPy’s `linalg` submodule.\n",
    "\n",
    "All of these routines are Python front ends to time-tested and highly optimized FORTRAN code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "id": "6zz7VUtmNdkO",
    "outputId": "5ca253ca-eae9-4d50-8b0f-e02963536bbd"
   },
   "outputs": [],
   "source": [
    "A = ((1, 2), (3, 4))\n",
    "A = np.array(A)\n",
    "y = np.ones((2, 1))  # Column vector\n",
    "det(A)  # Check that A is nonsingular, and hence invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "id": "SUW7b39jNdkO",
    "outputId": "68ec426d-0860-4400-9a4c-c82554a22ef2"
   },
   "outputs": [],
   "source": [
    "A_inv = inv(A)  # Compute the inverse\n",
    "A_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "id": "nLcToKpcNdkP",
    "outputId": "95c0b5eb-2f13-4fb4-bf89-436ee19d6ef1"
   },
   "outputs": [],
   "source": [
    "x = A_inv @ y  # Solution\n",
    "A @ x          # Should equal y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "id": "MWgrA67nNdkP",
    "outputId": "93c727a6-00f0-48bc-de40-d7b188e1960c"
   },
   "outputs": [],
   "source": [
    "solve(A, y)  # Produces the same solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQd7TxKfNdkQ"
   },
   "source": [
    "Observe how we can solve for $ x = A^{-1} y $ by either via `inv(A) @ y`, or using `solve(A, y)`.\n",
    "\n",
    "The latter method uses a different algorithm (LU decomposition) that is numerically more stable, and hence should almost always be preferred.\n",
    "\n",
    "To obtain the least-squares solution $ \\hat x = (A'A)^{-1}A'y $, use `scipy.linalg.lstsq(A, y)`.\n",
    "\n",
    "\n",
    "<a id='la-eigen'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "By85k9XYNdkQ"
   },
   "source": [
    "# Some Mathematical Properties\n",
    "\n",
    "We round out our discussion by briefly mentioning several other important\n",
    "topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3DLS9xZNdkQ"
   },
   "source": [
    "### Series Expansions\n",
    "\n",
    "\n",
    "<a id='index-20'></a>\n",
    "Recall the usual summation formula for a geometric progression, which states\n",
    "that if $ |a| < 1 $, then $ \\sum_{k=0}^{\\infty} a^k = (1 - a)^{-1} $.\n",
    "\n",
    "A generalization of this idea exists in the matrix setting.\n",
    "\n",
    "\n",
    "<a id='la-mn'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZeAgB8hNdkQ"
   },
   "source": [
    "#### Matrix Norms\n",
    "\n",
    "\n",
    "<a id='index-21'></a>\n",
    "Let $ A $ be a square matrix, and let\n",
    "\n",
    "$$\n",
    "\\| A \\| := \\max_{\\| x \\| = 1} \\| A x \\|\n",
    "$$\n",
    "\n",
    "The norms on the right-hand side are ordinary vector norms, while the norm on\n",
    "the left-hand side is a *matrix norm* — in this case, the so-called\n",
    "*spectral norm*.\n",
    "\n",
    "For example, for a square matrix $ S $, the condition $ \\| S \\| < 1 $ means that $ S $ is *contractive*, in the sense that it pulls all vectors towards the origin <sup><a href=#cfn id=cfn-link>[2]</a></sup>.\n",
    "\n",
    "\n",
    "<a id='la-neumann'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBimuOAjNdkR"
   },
   "source": [
    "### Positive Definite Matrices\n",
    "\n",
    "\n",
    "<a id='index-27'></a>\n",
    "Let $ A $ be a symmetric $ n \\times n $ matrix.\n",
    "\n",
    "We say that $ A $ is\n",
    "\n",
    "1. *positive definite* if $ x' A x > 0 $ for every $ x \\in \\mathbb R ^n \\setminus \\{0\\} $  \n",
    "1. *positive semi-definite* or *nonnegative definite* if $ x' A x \\geq 0 $ for every $ x \\in \\mathbb R ^n $  \n",
    "\n",
    "\n",
    "Analogous definitions exist for negative definite and negative semi-definite matrices.\n",
    "\n",
    "It is notable that if $ A $ is positive definite, then all of its eigenvalues\n",
    "are strictly positive, and hence $ A $ is invertible (with positive\n",
    "definite inverse).\n",
    "\n",
    "\n",
    "<a id='la-mcalc'></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_matrices.ipynb",
   "provenance": []
  },
  "date": 1608594544.0680027,
  "filename": "linear_algebra.rst",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "next_doc": {
   "link": "complex_and_trig",
   "title": "Complex Numbers and Trigonometry"
  },
  "prev_doc": {
   "link": "sir_model",
   "title": "Modeling COVID 19"
  },
  "title": "Linear Algebra"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
